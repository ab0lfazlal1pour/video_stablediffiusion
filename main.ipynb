{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87c26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8298d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\n",
      "   Ø±Ø²ÙˆÙ„ÛŒÙˆØ´Ù† Ù†Ù‡Ø§ÛŒÛŒ: 720x1280\n",
      "   Ù…Ø¯Øª Ø²Ù…Ø§Ù†: 3 Ø«Ø§Ù†ÛŒÙ‡\n",
      "   ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…: 18\n",
      "   FPS: 6\n",
      "   Decode chunk size: 2\n",
      "   Ø­Ø§ÙØ¸Ù‡ GPU: 5.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Ø³Ù„ÙˆÙ„ 1: ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡\n",
    "import torch\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "class OptimizedVideoConfig:\n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø²ÙˆÙ„ÛŒÙˆØ´Ù† (Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ RTX 4050)\n",
    "    OUTPUT_WIDTH = 720       # Ú©Ø§Ù‡Ø´ Ø§Ø² 1080 Ø¨Ù‡ 720\n",
    "    OUTPUT_HEIGHT = 1280     # Ú©Ø§Ù‡Ø´ Ø§Ø² 1920 Ø¨Ù‡ 1280\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø²Ù…Ø§Ù† (Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡)\n",
    "    DURATION_SECONDS = 3     # Ú©Ø§Ù‡Ø´ Ø§Ø² 5 Ø¨Ù‡ 3 Ø«Ø§Ù†ÛŒÙ‡\n",
    "    FPS = 6                  # Ø­ÙØ¸ Ù‡Ù…Ø§Ù† FPS\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø­Ø§ÙØ¸Ù‡ (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡)\n",
    "    ENABLE_CPU_OFFLOAD = True\n",
    "    ENABLE_MEMORY_EFFICIENT = True\n",
    "    ENABLE_SEQUENTIAL_OFFLOAD = True\n",
    "    USE_FP16 = True\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
    "    DECODE_CHUNK_SIZE = 2    # Ú©Ø§Ù‡Ø´ Ø§Ø² 8 Ø¨Ù‡ 2\n",
    "    ENABLE_ATTENTION_SLICING = True\n",
    "    LOW_VRAM_MODE = True\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©ÛŒÙÛŒØª (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡)\n",
    "    UPSCALE_METHOD = \"bicubic\"  # ØªØºÛŒÛŒØ± Ø§Ø² realesrgan Ø¨Ù‡ bicubic\n",
    "    GUIDANCE_SCALE = 7.5        # Ú©Ø§Ù‡Ø´ Ø§Ø² 10.0\n",
    "    MOTION_BUCKET_ID = 127\n",
    "    NOISE_AUG_STRENGTH = 0.02\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯ÛŒÚ¯Ø±\n",
    "    SEED = 42\n",
    "    SAVE_FRAMES = False\n",
    "    OUTPUT_FORMAT = \"mp4\"\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ batch\n",
    "    BATCH_SIZE = 1\n",
    "    MAX_MEMORY_ALLOCATED = 0.8  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 80% Ø­Ø§ÙØ¸Ù‡ GPU\n",
    "\n",
    "config = OptimizedVideoConfig()\n",
    "\n",
    "# Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§\n",
    "TOTAL_FRAMES = int(config.DURATION_SECONDS * config.FPS)\n",
    "print(f\"ğŸ“Š ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡:\")\n",
    "print(f\"   Ø±Ø²ÙˆÙ„ÛŒÙˆØ´Ù† Ù†Ù‡Ø§ÛŒÛŒ: {config.OUTPUT_WIDTH}x{config.OUTPUT_HEIGHT}\")\n",
    "print(f\"   Ù…Ø¯Øª Ø²Ù…Ø§Ù†: {config.DURATION_SECONDS} Ø«Ø§Ù†ÛŒÙ‡\")\n",
    "print(f\"   ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…: {TOTAL_FRAMES}\")\n",
    "print(f\"   FPS: {config.FPS}\")\n",
    "print(f\"   Decode chunk size: {config.DECODE_CHUNK_SIZE}\")\n",
    "\n",
    "# Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø§ÙØ¸Ù‡ GPU\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"   Ø­Ø§ÙØ¸Ù‡ GPU: {gpu_memory:.1f} GB\")\n",
    "        return gpu_memory\n",
    "    return 0\n",
    "\n",
    "gpu_memory = check_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e117457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø­Ø¯ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# Ø³Ù„ÙˆÙ„ 2: ØªÙˆØ§Ø¨Ø¹ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡\n",
    "def clear_memory():\n",
    "    \"\"\"Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ GPU Ùˆ CPU\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def get_memory_info():\n",
    "    \"\"\"Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø­Ø§ÙØ¸Ù‡\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        \n",
    "        print(f\"ğŸ§  Ø­Ø§ÙØ¸Ù‡ GPU:\")\n",
    "        print(f\"   ØªØ®ØµÛŒØµ ÛŒØ§ÙØªÙ‡: {allocated:.2f} GB\")\n",
    "        print(f\"   Ú©Ø´ Ø´Ø¯Ù‡: {cached:.2f} GB\")\n",
    "        print(f\"   Ú©Ù„: {total:.2f} GB\")\n",
    "        print(f\"   Ø¯Ø±ØµØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: {(allocated/total)*100:.1f}%\")\n",
    "        \n",
    "        return allocated, cached, total\n",
    "    return 0, 0, 0\n",
    "\n",
    "def optimize_torch_settings():\n",
    "    \"\"\"Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª PyTorch\"\"\"\n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø­Ø§ÙØ¸Ù‡\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª deterministic Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª garbage collection\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # ØªÙ†Ø¸ÛŒÙ… Ø­Ø¯ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
    "    if torch.cuda.is_available():\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "        memory_fraction = config.MAX_MEMORY_ALLOCATED\n",
    "        torch.cuda.set_per_process_memory_fraction(memory_fraction)\n",
    "        print(f\"âœ… Ø­Ø¯ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡: {memory_fraction*100}%\")\n",
    "\n",
    "optimize_torch_settings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee901ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø³Ù„ÙˆÙ„ 3: Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡\n",
    "def load_optimized_model():\n",
    "    \"\"\"Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡\"\"\"\n",
    "    print(\"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ù„ÙˆØ¯ Ù…Ø¯Ù„ SVD-XT Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡...\")\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    try:\n",
    "        from diffusers import StableVideoDiffusionPipeline\n",
    "        \n",
    "        # Ù„ÙˆØ¯ pipeline Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡\n",
    "        pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "            \"stabilityai/stable-video-diffusion-img2vid-xt\",\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        \n",
    "        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙØ¸Ù‡\n",
    "        if config.ENABLE_CPU_OFFLOAD:\n",
    "            pipe.enable_model_cpu_offload()\n",
    "            print(\"âœ… CPU offloading ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
    "        \n",
    "        if config.ENABLE_SEQUENTIAL_OFFLOAD:\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"âœ… Sequential CPU offload ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Sequential offload Ø®Ø·Ø§: {e}\")\n",
    "        \n",
    "        if config.ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing(1)  # slice_size=1 Ø¨Ø±Ø§ÛŒ Ú©Ù…ØªØ±ÛŒÙ† Ù…ØµØ±Ù\n",
    "            print(\"âœ… Attention slicing ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
    "        \n",
    "        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ VAE\n",
    "        try:\n",
    "            pipe.vae.enable_slicing()\n",
    "            print(\"âœ… VAE slicing ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
    "        except:\n",
    "            print(\"âš ï¸ VAE slicing Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\")\n",
    "        \n",
    "        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ UNet\n",
    "        try:\n",
    "            pipe.unet.enable_forward_chunking(chunk_size=1)\n",
    "            print(\"âœ… UNet forward chunking ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
    "        except:\n",
    "            print(\"âš ï¸ UNet chunking Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\")\n",
    "        \n",
    "        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª low VRAM\n",
    "        if config.LOW_VRAM_MODE:\n",
    "            try:\n",
    "                pipe.enable_vae_slicing()\n",
    "                pipe.enable_vae_tiling()\n",
    "                print(\"âœ… VAE tiling ÙØ¹Ø§Ù„ Ø´Ø¯\")\n",
    "            except:\n",
    "                print(\"âš ï¸ VAE tiling Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\")\n",
    "        \n",
    "        print(\"âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ Ù„ÙˆØ¯ Ø´Ø¯\")\n",
    "        \n",
    "        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù„ÙˆØ¯\n",
    "        get_memory_info()\n",
    "        \n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ù…Ø¯Ù„: {e}\")\n",
    "        clear_memory()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "514ac1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø³Ù„ÙˆÙ„ 4: ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡\n",
    "def generate_optimized_video(pipe, image_path, output_path=\"optimized_video.mp4\"):\n",
    "    \"\"\"ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¬ Ø´Ø±ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡...\")\n",
    "    \n",
    "    try:\n",
    "        from diffusers.utils import load_image\n",
    "        from PIL import Image\n",
    "        import numpy as np\n",
    "        import imageio\n",
    "        \n",
    "        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹\n",
    "        clear_memory()\n",
    "        \n",
    "        # Ù„ÙˆØ¯ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ú©Ø³\n",
    "        print(\"ğŸ“¸ Ù„ÙˆØ¯ Ø¹Ú©Ø³...\")\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ù‡ Ø±Ø²ÙˆÙ„ÛŒÙˆØ´Ù† Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
    "        optimal_width, optimal_height = 768, 432  # Ú©Ø§Ù‡Ø´ Ø§Ø² 1024x576\n",
    "        image = image.resize((optimal_width, optimal_height), Image.LANCZOS)\n",
    "        \n",
    "        # ØªÙ†Ø¸ÛŒÙ… generator\n",
    "        generator = torch.manual_seed(config.SEED) if config.SEED else None\n",
    "        \n",
    "        print(f\"ğŸ”„ ØªÙˆÙ„ÛŒØ¯ {TOTAL_FRAMES} ÙØ±ÛŒÙ…...\")\n",
    "        print(\"â³ Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯...\")\n",
    "        \n",
    "        # ØªÙˆÙ„ÛŒØ¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡\n",
    "        with torch.no_grad():  # Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
    "            frames = pipe(\n",
    "                image,\n",
    "                decode_chunk_size=config.DECODE_CHUNK_SIZE,\n",
    "                generator=generator,\n",
    "                motion_bucket_id=config.MOTION_BUCKET_ID,\n",
    "                noise_aug_strength=config.NOISE_AUG_STRENGTH,\n",
    "                num_frames=TOTAL_FRAMES,\n",
    "                num_inference_steps=20,  # Ú©Ø§Ù‡Ø´ Ø§Ø² 25 Ø¨Ù‡ 20\n",
    "                output_type=\"pil\"\n",
    "            ).frames[0]\n",
    "        \n",
    "        print(f\"âœ… {len(frames)} ÙØ±ÛŒÙ… ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯\")\n",
    "        \n",
    "        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² ØªÙˆÙ„ÛŒØ¯\n",
    "        clear_memory()\n",
    "        \n",
    "        # Upscaling Ø¨Ù‡ Ø±Ø²ÙˆÙ„ÛŒÙˆØ´Ù† Ù†Ù‡Ø§ÛŒÛŒ\n",
    "        if config.OUTPUT_WIDTH != optimal_width or config.OUTPUT_HEIGHT != optimal_height:\n",
    "            print(\"ğŸ”„ ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§...\")\n",
    "            upscaled_frames = []\n",
    "            \n",
    "            for i, frame in enumerate(frames):\n",
    "                # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÛŒÙ… Ø¨Ù‡ ÙØ±ÛŒÙ…\n",
    "                frame_resized = frame.resize(\n",
    "                    (config.OUTPUT_WIDTH, config.OUTPUT_HEIGHT), \n",
    "                    Image.LANCZOS\n",
    "                )\n",
    "                upscaled_frames.append(frame_resized)\n",
    "                \n",
    "                # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ù‡Ø± 5 ÙØ±ÛŒÙ…\n",
    "                if i % 5 == 0:\n",
    "                    clear_memory()\n",
    "                    print(f\"   ÙØ±ÛŒÙ… {i+1}/{len(frames)} Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯\")\n",
    "            \n",
    "            frames = upscaled_frames\n",
    "            del upscaled_frames\n",
    "        \n",
    "        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ numpy array\n",
    "        print(\"ğŸ¥ Ø°Ø®ÛŒØ±Ù‡ ÙˆÛŒØ¯ÛŒÙˆ...\")\n",
    "        frames_array = []\n",
    "        \n",
    "        for i, frame in enumerate(frames):\n",
    "            frames_array.append(np.array(frame))\n",
    "            \n",
    "            # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ù‡Ø± 3 ÙØ±ÛŒÙ…\n",
    "            if i % 3 == 0:\n",
    "                clear_memory()\n",
    "        \n",
    "        # Ø°Ø®ÛŒØ±Ù‡ ÙˆÛŒØ¯ÛŒÙˆ\n",
    "        imageio.mimsave(\n",
    "            output_path,\n",
    "            frames_array,\n",
    "            fps=config.FPS,\n",
    "            quality=7,  # Ú©Ø§Ù‡Ø´ Ú©ÛŒÙÛŒØª Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ú©ÙˆÚ†Ú©ØªØ±\n",
    "            codec='libx264',\n",
    "            macro_block_size=16\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… ÙˆÛŒØ¯ÛŒÙˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {output_path}\")\n",
    "        \n",
    "        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¬Ù… ÙØ§ÛŒÙ„\n",
    "        file_size = os.path.getsize(output_path) / (1024 * 1024)\n",
    "        print(f\"ğŸ“Š Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {file_size:.2f} MB\")\n",
    "        \n",
    "        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "        del frames, frames_array\n",
    "        clear_memory()\n",
    "        \n",
    "        return output_path\n",
    "        \n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø§ÛŒ Ú©Ù…Ø¨ÙˆØ¯ Ø­Ø§ÙØ¸Ù‡ CUDA: {e}\")\n",
    "        print(\"ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:\")\n",
    "        print(\"   - ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯\")\n",
    "        print(\"   - Ø±Ø²ÙˆÙ„ÛŒÙˆØ´Ù† Ø±Ø§ Ú©Ù…ØªØ± Ú©Ù†ÛŒØ¯\")\n",
    "        print(\"   - decode_chunk_size Ø±Ø§ Ú©Ù…ØªØ± Ú©Ù†ÛŒØ¯\")\n",
    "        clear_memory()\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ø®Ø·Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ: {e}\")\n",
    "        clear_memory()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83148896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª ØªØ³Øª Ø³Ø±ÛŒØ¹ Ø­Ø§ÙØ¸Ù‡...\n",
      "ğŸ§  Ø­Ø§ÙØ¸Ù‡ GPU:\n",
      "   ØªØ®ØµÛŒØµ ÛŒØ§ÙØªÙ‡: 0.01 GB\n",
      "   Ú©Ø´ Ø´Ø¯Ù‡: 0.02 GB\n",
      "   Ú©Ù„: 5.65 GB\n",
      "   Ø¯Ø±ØµØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: 0.1%\n",
      "âœ… Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ø§Ø³Øª. Ø¢Ø²Ø§Ø¯: 5.6GB\n"
     ]
    }
   ],
   "source": [
    "# Ø³Ù„ÙˆÙ„ 5: ØªØ³Øª Ø³Ø±ÛŒØ¹\n",
    "def quick_test():\n",
    "    \"\"\"ØªØ³Øª Ø³Ø±ÛŒØ¹ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯\"\"\"\n",
    "    print(\"ğŸ§ª ØªØ³Øª Ø³Ø±ÛŒØ¹ Ø­Ø§ÙØ¸Ù‡...\")\n",
    "    \n",
    "    # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆØ¬ÙˆØ¯\n",
    "    allocated, cached, total = get_memory_info()\n",
    "    \n",
    "    if total == 0:\n",
    "        print(\"âŒ CUDA Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\")\n",
    "        return False\n",
    "    \n",
    "    # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø§ÙØ¸Ù‡ Ø¢Ø²Ø§Ø¯\n",
    "    free_memory = total - allocated\n",
    "    required_memory = 3.0  # GB ØªÙ‚Ø±ÛŒØ¨ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²\n",
    "    \n",
    "    if free_memory < required_memory:\n",
    "        print(f\"âš ï¸ Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª. Ø¢Ø²Ø§Ø¯: {free_memory:.1f}GBØŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: {required_memory}GB\")\n",
    "        print(\"ğŸ’¡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:\")\n",
    "        print(f\"   - DURATION_SECONDS = {max(1, config.DURATION_SECONDS-1)}\")\n",
    "        print(f\"   - OUTPUT_WIDTH = {config.OUTPUT_WIDTH//2}\")\n",
    "        print(f\"   - OUTPUT_HEIGHT = {config.OUTPUT_HEIGHT//2}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"âœ… Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ø§Ø³Øª. Ø¢Ø²Ø§Ø¯: {free_memory:.1f}GB\")\n",
    "    return True\n",
    "\n",
    "# Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª\n",
    "test_result = quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "083d8b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Ú©Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!\n",
      "ğŸ“ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:\n",
      "   result = run_optimized_generation('path/to/your/image.jpg')\n"
     ]
    }
   ],
   "source": [
    "# Ø³Ù„ÙˆÙ„ 6: Ø§Ø¬Ø±Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "def run_optimized_generation(image_path):\n",
    "    \"\"\"Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡\"\"\"\n",
    "    \n",
    "    # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø­Ø§ÙØ¸Ù‡\n",
    "    if not quick_test():\n",
    "        return None\n",
    "    \n",
    "    # Ù„ÙˆØ¯ Ù…Ø¯Ù„\n",
    "    pipe = load_optimized_model()\n",
    "    if pipe is None:\n",
    "        return None\n",
    "    \n",
    "    # ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ\n",
    "    result = generate_optimized_video(pipe, image_path)\n",
    "    \n",
    "    # Ø¢Ø²Ø§Ø¯ Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ø§Ø² Ø­Ø§ÙØ¸Ù‡\n",
    "    del pipe\n",
    "    clear_memory()\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"\\nğŸš€ Ú©Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!\")\n",
    "print(\"ğŸ“ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:\")\n",
    "print(\"   result = run_optimized_generation('path/to/your/image.jpg')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac1028e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª ØªØ³Øª Ø³Ø±ÛŒØ¹ Ø­Ø§ÙØ¸Ù‡...\n",
      "ğŸ§  Ø­Ø§ÙØ¸Ù‡ GPU:\n",
      "   ØªØ®ØµÛŒØµ ÛŒØ§ÙØªÙ‡: 0.01 GB\n",
      "   Ú©Ø´ Ø´Ø¯Ù‡: 0.02 GB\n",
      "   Ú©Ù„: 5.65 GB\n",
      "   Ø¯Ø±ØµØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: 0.1%\n",
      "âœ… Ø­Ø§ÙØ¸Ù‡ Ú©Ø§ÙÛŒ Ø§Ø³Øª. Ø¢Ø²Ø§Ø¯: 5.6GB\n",
      "ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ù„ÙˆØ¯ Ù…Ø¯Ù„ SVD-XT Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf589c8c2f2b417eafa47c67e9dd31cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CPU offloading ÙØ¹Ø§Ù„ Ø´Ø¯\n",
      "âœ… Sequential CPU offload ÙØ¹Ø§Ù„ Ø´Ø¯\n",
      "âœ… Attention slicing ÙØ¹Ø§Ù„ Ø´Ø¯\n",
      "âš ï¸ VAE slicing Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\n",
      "âœ… UNet forward chunking ÙØ¹Ø§Ù„ Ø´Ø¯\n",
      "âš ï¸ VAE tiling Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª\n",
      "âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ Ù„ÙˆØ¯ Ø´Ø¯\n",
      "ğŸ§  Ø­Ø§ÙØ¸Ù‡ GPU:\n",
      "   ØªØ®ØµÛŒØµ ÛŒØ§ÙØªÙ‡: 0.01 GB\n",
      "   Ú©Ø´ Ø´Ø¯Ù‡: 0.02 GB\n",
      "   Ú©Ù„: 5.65 GB\n",
      "   Ø¯Ø±ØµØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: 0.1%\n",
      "ğŸ¬ Ø´Ø±ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡...\n",
      "ğŸ“¸ Ù„ÙˆØ¯ Ø¹Ú©Ø³...\n",
      "ğŸ”„ ØªÙˆÙ„ÛŒØ¯ 18 ÙØ±ÛŒÙ…...\n",
      "â³ Ø§ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ad1ac414c24aff946ba3cb09b64793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 18 ÙØ±ÛŒÙ… ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯\n",
      "ğŸ”„ ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§...\n",
      "   ÙØ±ÛŒÙ… 1/18 Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯\n",
      "   ÙØ±ÛŒÙ… 6/18 Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯\n",
      "   ÙØ±ÛŒÙ… 11/18 Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯\n",
      "   ÙØ±ÛŒÙ… 16/18 Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯\n",
      "ğŸ¥ Ø°Ø®ÛŒØ±Ù‡ ÙˆÛŒØ¯ÛŒÙˆ...\n",
      "âœ… ÙˆÛŒØ¯ÛŒÙˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: optimized_video.mp4\n",
      "ğŸ“Š Ø­Ø¬Ù… ÙØ§ÛŒÙ„: 2.54 MB\n"
     ]
    }
   ],
   "source": [
    "result = run_optimized_generation('pics/Marcello_Bacciarelli_-_Alcibiades_Being_Taught_by_Socrates,_1776-77_crop.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e0217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
